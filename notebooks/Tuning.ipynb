{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac38da57",
   "metadata": {},
   "source": [
    "A custom split() method allows you to:\n",
    "\n",
    "- Preserve temporal order.\n",
    "\n",
    "- Do walk-forward validation:\n",
    "\n",
    "    Train on earlier time steps.\n",
    "\n",
    "    Validate on slightly later ones.\n",
    "\n",
    "    Keep expanding the training window step by step.\n",
    "\n",
    "- Avoid data leakage.\n",
    "- And i have more control over splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19b7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from typing import Generator, Tuple, Sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Logarithmic Error (RMSLE).\n",
    "    \n",
    "    Measures error on a log scale, which means it penalizes relative differences rather than absolute differences.\"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def log_transform(y):\n",
    "    \"\"\"Apply logarithmic transformation to the target variable.\n",
    "     log(0) is undefined; adding 1 handles zero targets gracefully\n",
    "    \"\"\"\n",
    "    return np.log1p(y)\n",
    "\n",
    "def inverse_log_transform(y):\n",
    "    \"\"\"\n",
    "    Inverse the logarithmic transformation applied to the target variable.\n",
    "    Converts the predictions back to the original scale.\"\"\"\n",
    "    return np.expm1(y)\n",
    "\n",
    "class TimeSeriesCV:\n",
    "    \"\"\"Custom Time Series Cross-Validation for Walk-forward Validation.\n",
    "        \n",
    "        This splitter generates train/test indices by expanding the training set\n",
    "        and sliding the test set forward in time.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_splits=5, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Initialize TimeSeriesCV.\n",
    "\n",
    "        Parameters:\n",
    "            n_splits (int): Number of walk-forward splits. Must be > 0.\n",
    "            test_size (float): Proportion of the dataset to use for validation in each split.\n",
    "                               Must be between 0 and 1 (exclusive).\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If parameters are outside of valid range.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(n_splits, int) or n_splits <= 0:\n",
    "            raise ValueError(\"n_splits must be a positive integer.\")\n",
    "        if not (0 < test_size < 1):\n",
    "            raise ValueError(\"test_size must be a float between 0 and 1 (exclusive).\")\n",
    "        \n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def split(self, X: Sequence) -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n",
    "        \"\"\"\n",
    "        Generate (train, validation) indices for each split.\n",
    "\n",
    "        Parameters:\n",
    "            X (Sequence): The input data (e.g., list, NumPy array, pandas DataFrame).\n",
    "                          Must support len() and indexing (X[i]).\n",
    "\n",
    "        Returns:\n",
    "            Generator yielding tuples of (train_indices, validation_indices) as numpy arrays.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If dataset is too small to be split according to given parameters.\n",
    "        \"\"\"\n",
    "        n_samples = len(X)\n",
    "        test_size = int(n_samples * self.test_size)\n",
    "        if test_size == 0:\n",
    "            raise ValueError(\"test_size too small; resulted in 0 validation samples.\")\n",
    "        if n_samples <= test_size:\n",
    "            raise ValueError(\"Dataset too small relative to test_size.\")\n",
    "        \n",
    "        step_size = (n_samples - test_size) // self.n_splits\n",
    "        if step_size <= 0:\n",
    "            raise ValueError(\"Number of splits too large for dataset size and test_size.\")\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            start_idx = i * step_size\n",
    "            train_end = start_idx + n_samples - test_size - step_size\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "\n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "\n",
    "            yield np.arange(start_idx, train_end), np.arange(test_start, test_end)\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length, target_col):\n",
    "    \"\"\"Create sequences of data for LSTM input.\n",
    "    :param data: Input data as a NumPy array or DataFrame.\n",
    "    :param seq_length: Length of the sequences to create.\n",
    "    :param target_col: Index of the target column in the data.\n",
    "    :return: Tuple of sequences (X) and targets (y).\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length, target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "def train_catboost(X_train, y_train, X_val, y_val, params, cat_features=None):\n",
    "    \"\"\"\n",
    "    Train a CatBoostRegressor model and predict on validation data.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (array-like or DataFrame): Training features.\n",
    "        y_train (array-like or Series): Training target values.\n",
    "        X_val (array-like or DataFrame): Validation features.\n",
    "        y_val (array-like or Series): Validation target values (used for shape checking).\n",
    "        params (dict): Parameters for CatBoostRegressor.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predictions for X_val.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input data dimensions do not match.\n",
    "        Exception: If model training or prediction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "    \n",
    "        if len(X_train) != len(y_train):\n",
    "            raise ValueError(\"X_train and y_train must have the same number of samples.\")\n",
    "        if len(X_val) != len(y_val):\n",
    "            raise ValueError(\"X_val and y_val must have the same number of samples.\")\n",
    "        model = cb.CatBoostRegressor(**params)\n",
    "        model.fit(X_train, y_train, cat_features=cat_features, verbose=0)\n",
    "        preds = model.predict(X_val)\n",
    "        return preds\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error in train_catboost: {e}\")\n",
    "        raise\n",
    "\n",
    "def train_lightgbm(X_train, y_train, X_val, y_val, params):\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    model = lgb.train(params, train_data, valid_sets=[val_data], num_boost_round=200, verbose_eval=False)\n",
    "    return model.predict(X_val)\n",
    "\n",
    "\n",
    "def train_lstm(X_train, y_train, X_val, y_val, input_shape, params):\n",
    "    model = Sequential([\n",
    "        LSTM(params['lstm_units'], return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(params['dropout_rate']),\n",
    "        LSTM(params['lstm_units'] // 2, return_sequences=False),\n",
    "        Dropout(params['dropout_rate']),\n",
    "        Dense(params['dense_units'], activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']), loss='mse')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=15,  # Reduce during tuning\n",
    "              batch_size=params['batch_size'],\n",
    "              verbose=0,\n",
    "              callbacks=[early_stopping])\n",
    "    \n",
    "    pred = model.predict(X_val, verbose=0)\n",
    "    \n",
    "    tf.keras.backend.clear_session()  # better after training to fully release resources\n",
    "    \n",
    "    return pred.flatten(), model\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_model(model_func, X, y, params:dict, cv, is_lstm=False, seq_length=10):\n",
    "    \"\"\"Evaluate a model using cross-validation.\n",
    "    parameters:\n",
    "        model_func: Function to train and predict with the model.\n",
    "        X: Features as a DataFrame or NumPy array.\n",
    "        y: Target values as a Series or NumPy array.\n",
    "        params: Dictionary of model parameters.\n",
    "        cv: Cross-validation splitter (e.g., TimeSeriesCV).\n",
    "        is_lstm: Boolean indicating if the model is LSTM.\n",
    "        seq_length: Length of sequences for LSTM (default is 10).\n",
    "        Returns:\n",
    "        Mean RMSE across all folds.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        try:\n",
    "            if is_lstm:\n",
    "                X_tr = X[train_idx]\n",
    "                y_tr = y[train_idx]\n",
    "                X_val = X[val_idx]\n",
    "                y_val = y[val_idx]\n",
    "\n",
    "                \n",
    "                y_pred_log = model_func(X_tr, y_tr, X_val, y_val, (X_tr.shape[1], X_tr.shape[2]), params)\n",
    "\n",
    "                y_pred = np.expm1(y_pred_log)  \n",
    "                y_true = np.expm1(y_val)\n",
    "                score = rmse(y_true, y_pred)\n",
    "            else:\n",
    "                X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "                y_tr_log = log_transform(y_tr)\n",
    "                y_val_log = log_transform(y_val)\n",
    "            \n",
    "                y_pred_log = model_func(X_tr, y_tr_log, X_val, y_val_log, params)\n",
    "                y_pred = inverse_log_transform(y_pred_log)\n",
    "                y_true = y_val.values\n",
    "                score = rmsle(y_true, y_pred)\n",
    "\n",
    "            scores.append(score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error during fold: {e}\")\n",
    "            continue\n",
    "\n",
    "    return np.mean(scores) if scores else float('inf')\n",
    "\n",
    "\n",
    "def get_objective(model_type, X, y, cv, seq_length):\n",
    "    \"\"\"Get the objective function for Optuna optimization based on model type.\n",
    "    Parameters:\n",
    "        model_type: Type of model to optimize ('catboost', 'lightgbm', 'lstm').\n",
    "        X: Features as a DataFrame or NumPy array.\n",
    "        y: Target values as a Series or NumPy array.\n",
    "        cv: Cross-validation splitter (e.g., TimeSeriesCV).\n",
    "        seq_length: Length of sequences for LSTM (default is 10).\n",
    "        Returns:\n",
    "        Objective function for Optuna optimization.\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        if model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 200, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "                'border_count': trial.suggest_int('border_count', 32, 128),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "                'random_strength': trial.suggest_float('random_strength', 0, 1),\n",
    "                'verbose': False,\n",
    "                'random_seed': 42\n",
    "            }\n",
    "            cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "            return evaluate_model(lambda X_train, y_train, X_val, y_val, p: train_catboost(X_train, y_train, X_val, y_val, p, cat_features), X, y, params, cv)\n",
    "\n",
    "        elif model_type == 'lightgbm':\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "                'verbose': -1,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            return evaluate_model(train_lightgbm, X, y, params, cv)\n",
    "\n",
    "        elif model_type == 'lstm':\n",
    "            params = {\n",
    "                'lstm_units': trial.suggest_int('lstm_units', 32, 128),\n",
    "                'dense_units': trial.suggest_int('dense_units', 16, 128),\n",
    "                'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.01, log=True),\n",
    "                'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "\n",
    "            }\n",
    "            return evaluate_model(train_lstm, X, y, params, cv, is_lstm=True, seq_length=seq_length)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "def run_optimization(model_type, X, y, n_trials=50, cv_folds=5, seq_length=10):\n",
    "    \"\"\"Run Optuna optimization for the specified model type.\n",
    "    Parameters:\n",
    "        model_type: Type of model to optimize ('catboost', 'lightgbm', 'lstm').\n",
    "        X: Features as a DataFrame or NumPy array.\n",
    "        y: Target values as a Series or NumPy array.\n",
    "        n_trials: Number of trials for Optuna optimization.\n",
    "        cv_folds: Number of folds for cross-validation.\n",
    "        seq_length: Length of sequences for LSTM (default is 10).\n",
    "        Returns:\n",
    "        Optuna study object with the best parameters and RMSE.\n",
    "    \"\"\"\n",
    "    cv = TimeSeriesCV(n_splits=cv_folds)\n",
    "    base_objective = get_objective(model_type, X, y, cv, seq_length)\n",
    "\n",
    "    def printing_objective(trial):\n",
    "        score = base_objective(trial)\n",
    "        print(f\"Trial {trial.number}: RMSE={score:.4f}, params={trial.params}\")\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(printing_objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    print(f\"\\n Best parameters for {model_type}:\")\n",
    "    print(study.best_params)\n",
    "    print(f\"RMSLE: {study.best_value:.4f}\")\n",
    "    return study\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70feac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path().resolve()\n",
    "python_files_dir = current_dir.parent / \"Python_Files\"\n",
    "if str(python_files_dir) not in sys.path:\n",
    "    sys.path.append(str(python_files_dir))\n",
    "\n",
    "from config import CFG\n",
    "from helpers import load_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcdf5d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found: C/Users/seydaaybar/Desktop/ntt_data/data/transaction.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ntt_data/helpers.py:20\u001b[0m, in \u001b[0;36mload_all_data\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_transaction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_transaction_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_test\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(cfg\u001b[38;5;241m.\u001b[39mdf_test_path)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/invent_env310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/invent_env310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/invent_env310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/invent_env310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/invent_env310/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C/Users/seydaaybar/Desktop/ntt_data/data/transaction.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_new\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/Desktop/ntt_data/helpers.py:31\u001b[0m, in \u001b[0;36mload_all_data\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     28\u001b[0m         data[key] \u001b[38;5;241m=\u001b[39m drop_columns(data[key], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File not found: C/Users/seydaaybar/Desktop/ntt_data/data/transaction.csv"
     ]
    }
   ],
   "source": [
    "data = load_all_data(CFG)\n",
    "\n",
    "df = data['df_new']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-10 16:13:35,588] A new study created in memory with name: no-name-f559f2ce-2aa8-4146-a1b4-26dd817c53e4\n",
      "Best trial: 0. Best value: 0.583548:  20%|██        | 1/5 [02:08<08:35, 128.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: RMSE=0.5835, params={'iterations': 855, 'learning_rate': 0.015255813626123587, 'depth': 8, 'l2_leaf_reg': 7.616317063084429, 'border_count': 40, 'min_data_in_leaf': 22, 'bagging_temperature': 0.7525659190873778, 'random_strength': 0.6677000851423287}\n",
      "[I 2025-07-10 16:15:44,386] Trial 0 finished with value: 0.5835481268794027 and parameters: {'iterations': 855, 'learning_rate': 0.015255813626123587, 'depth': 8, 'l2_leaf_reg': 7.616317063084429, 'border_count': 40, 'min_data_in_leaf': 22, 'bagging_temperature': 0.7525659190873778, 'random_strength': 0.6677000851423287}. Best is trial 0 with value: 0.5835481268794027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.578825:  40%|████      | 2/5 [02:45<03:43, 74.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: RMSE=0.5788, params={'iterations': 383, 'learning_rate': 0.08225703868286412, 'depth': 5, 'l2_leaf_reg': 9.944359434041193, 'border_count': 69, 'min_data_in_leaf': 54, 'bagging_temperature': 0.5419965715599584, 'random_strength': 0.17570423922635958}\n",
      "[I 2025-07-10 16:16:20,933] Trial 1 finished with value: 0.5788253039370908 and parameters: {'iterations': 383, 'learning_rate': 0.08225703868286412, 'depth': 5, 'l2_leaf_reg': 9.944359434041193, 'border_count': 69, 'min_data_in_leaf': 54, 'bagging_temperature': 0.5419965715599584, 'random_strength': 0.17570423922635958}. Best is trial 1 with value: 0.5788253039370908.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.578825:  60%|██████    | 3/5 [04:38<03:04, 92.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: RMSE=0.5831, params={'iterations': 646, 'learning_rate': 0.11548799955502696, 'depth': 9, 'l2_leaf_reg': 6.581490358154209, 'border_count': 106, 'min_data_in_leaf': 26, 'bagging_temperature': 0.10457319284521527, 'random_strength': 0.861878792459167}\n",
      "[I 2025-07-10 16:18:14,538] Trial 2 finished with value: 0.5830688956429297 and parameters: {'iterations': 646, 'learning_rate': 0.11548799955502696, 'depth': 9, 'l2_leaf_reg': 6.581490358154209, 'border_count': 106, 'min_data_in_leaf': 26, 'bagging_temperature': 0.10457319284521527, 'random_strength': 0.861878792459167}. Best is trial 1 with value: 0.5788253039370908.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.578825:  80%|████████  | 4/5 [05:36<01:18, 78.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3: RMSE=0.5798, params={'iterations': 324, 'learning_rate': 0.14643256283839626, 'depth': 9, 'l2_leaf_reg': 9.822442463860943, 'border_count': 86, 'min_data_in_leaf': 80, 'bagging_temperature': 0.9225697336777582, 'random_strength': 0.6142576783266187}\n",
      "[I 2025-07-10 16:19:11,848] Trial 3 finished with value: 0.5798414443288518 and parameters: {'iterations': 324, 'learning_rate': 0.14643256283839626, 'depth': 9, 'l2_leaf_reg': 9.822442463860943, 'border_count': 86, 'min_data_in_leaf': 80, 'bagging_temperature': 0.9225697336777582, 'random_strength': 0.6142576783266187}. Best is trial 1 with value: 0.5788253039370908.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.578825: 100%|██████████| 5/5 [06:19<00:00, 75.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4: RMSE=0.5789, params={'iterations': 571, 'learning_rate': 0.24444877777267898, 'depth': 4, 'l2_leaf_reg': 6.122687932600137, 'border_count': 126, 'min_data_in_leaf': 90, 'bagging_temperature': 0.7829617145050419, 'random_strength': 0.11694542461367563}\n",
      "[I 2025-07-10 16:19:55,153] Trial 4 finished with value: 0.5788794007949043 and parameters: {'iterations': 571, 'learning_rate': 0.24444877777267898, 'depth': 4, 'l2_leaf_reg': 6.122687932600137, 'border_count': 126, 'min_data_in_leaf': 90, 'bagging_temperature': 0.7829617145050419, 'random_strength': 0.11694542461367563}. Best is trial 1 with value: 0.5788253039370908.\n",
      "\n",
      " Best parameters for catboost:\n",
      "{'iterations': 383, 'learning_rate': 0.08225703868286412, 'depth': 5, 'l2_leaf_reg': 9.944359434041193, 'border_count': 69, 'min_data_in_leaf': 54, 'bagging_temperature': 0.5419965715599584, 'random_strength': 0.17570423922635958}\n",
      "RMSE: 0.5788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x1a98ae39f30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_optimization('catboost', X_train, y_train, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900a4a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10716.0\n",
       "1        42864.0\n",
       "2        10716.0\n",
       "3        10716.0\n",
       "4        10716.0\n",
       "          ...   \n",
       "63768     1065.0\n",
       "63769     1356.0\n",
       "63770     1421.0\n",
       "63771     1746.0\n",
       "63772      582.0\n",
       "Name: sales, Length: 63773, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d89dee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1467090.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d34c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe5949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSLE: 1.6395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "y_true = y.values  # original target\n",
    "y_pred_baseline = np.full_like(y_true, y_true.mean())\n",
    "\n",
    "baseline_rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred_baseline))\n",
    "print(f\"Baseline RMSLE: {baseline_rmsle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba390201",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5de0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = np.load('X_train_lstm.npy')\n",
    "y_train_lstm = np.load('y_train_lstm.npy')\n",
    "X_val_lstm = np.load('X_val_lstm.npy')\n",
    "y_val_lstm = np.load('y_val_lstm.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f78efd",
   "metadata": {},
   "source": [
    "#### Check for NaN or Inf values in  input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa9c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lstm:\n",
      "  NaNs: 0\n",
      "  Infs: 0\n",
      "y_train_lstm:\n",
      "  NaNs: 0\n",
      "  Infs: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"X_train_lstm:\")\n",
    "print(\"  NaNs:\", np.isnan(X_train_lstm).sum())\n",
    "print(\"  Infs:\", np.isinf(X_train_lstm).sum())\n",
    "\n",
    "print(\"y_train_lstm:\")\n",
    "print(\"  NaNs:\", np.isnan(y_train_lstm).sum())\n",
    "print(\"  Infs:\", np.isinf(y_train_lstm).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ba5fa",
   "metadata": {},
   "source": [
    "#### Check the actual max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c8e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max X: 21326.0\n",
      "Min X: -6.118417947713259\n",
      "Max y: 5.3349249274041455\n",
      "Min y: -5.05778085876837\n"
     ]
    }
   ],
   "source": [
    "print(\"Max X:\", np.max(X_train_lstm))\n",
    "print(\"Min X:\", np.min(X_train_lstm))\n",
    "print(\"Max y:\", np.max(y_train_lstm))\n",
    "print(\"Min y:\", np.min(y_train_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b19ded75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-12 15:12:26,544] A new study created in memory with name: no-name-ed819684-20f5-4f65-9582-10bc006849a6\n",
      "Best trial: 0. Best value: 4.47272:  20%|██        | 1/5 [01:01<04:06, 61.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: RMSE=4.4727, params={'lstm_units': 81, 'dense_units': 70, 'dropout_rate': 0.2600919967351602, 'learning_rate': 0.002802301797380156, 'batch_size': 32}\n",
      "[I 2025-07-12 15:13:28,048] Trial 0 finished with value: 4.472720763849033 and parameters: {'lstm_units': 81, 'dense_units': 70, 'dropout_rate': 0.2600919967351602, 'learning_rate': 0.002802301797380156, 'batch_size': 32}. Best is trial 0 with value: 4.472720763849033.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 4.47272:  40%|████      | 2/5 [02:24<03:41, 73.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: RMSE=4.4736, params={'lstm_units': 80, 'dense_units': 53, 'dropout_rate': 0.2538710786217493, 'learning_rate': 0.002765593325579184, 'batch_size': 16}\n",
      "[I 2025-07-12 15:14:50,552] Trial 1 finished with value: 4.473612143581377 and parameters: {'lstm_units': 80, 'dense_units': 53, 'dropout_rate': 0.2538710786217493, 'learning_rate': 0.002765593325579184, 'batch_size': 16}. Best is trial 0 with value: 4.472720763849033.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 4.46337:  60%|██████    | 3/5 [05:10<03:52, 116.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: RMSE=4.4634, params={'lstm_units': 116, 'dense_units': 59, 'dropout_rate': 0.14724679263742732, 'learning_rate': 0.004834746313664063, 'batch_size': 16}\n",
      "[I 2025-07-12 15:17:37,510] Trial 2 finished with value: 4.463369775623137 and parameters: {'lstm_units': 116, 'dense_units': 59, 'dropout_rate': 0.14724679263742732, 'learning_rate': 0.004834746313664063, 'batch_size': 16}. Best is trial 2 with value: 4.463369775623137.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 4.46337:  80%|████████  | 4/5 [05:57<01:28, 88.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3: RMSE=4.4710, params={'lstm_units': 80, 'dense_units': 30, 'dropout_rate': 0.361799688179356, 'learning_rate': 0.007790321593912226, 'batch_size': 64}\n",
      "[I 2025-07-12 15:18:23,931] Trial 3 finished with value: 4.4710492897735215 and parameters: {'lstm_units': 80, 'dense_units': 30, 'dropout_rate': 0.361799688179356, 'learning_rate': 0.007790321593912226, 'batch_size': 64}. Best is trial 2 with value: 4.463369775623137.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 4.46337: 100%|██████████| 5/5 [07:27<00:00, 89.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4: RMSE=4.4667, params={'lstm_units': 70, 'dense_units': 102, 'dropout_rate': 0.23497516097044602, 'learning_rate': 0.004881999292116275, 'batch_size': 16}\n",
      "[I 2025-07-12 15:19:54,374] Trial 4 finished with value: 4.466659214328545 and parameters: {'lstm_units': 70, 'dense_units': 102, 'dropout_rate': 0.23497516097044602, 'learning_rate': 0.004881999292116275, 'batch_size': 16}. Best is trial 2 with value: 4.463369775623137.\n",
      "\n",
      " Best parameters for lstm:\n",
      "{'lstm_units': 116, 'dense_units': 59, 'dropout_rate': 0.14724679263742732, 'learning_rate': 0.004834746313664063, 'batch_size': 16}\n",
      "RMSLE: 4.4634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x1302eab30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_optimization('lstm', X_train_lstm, y_train_lstm, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "422c7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log sales stats: -5.05778085876837 5.3349249274041455 0.35551618838141263\n"
     ]
    }
   ],
   "source": [
    "print(\"Log sales stats:\", y_train_lstm.min(), y_train_lstm.max(), y_train_lstm.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be799a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e31f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96671513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seyda_works310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
